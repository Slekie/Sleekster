{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a25253e-be81-4e2e-848c-fcd88374689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\slick.aihs\\miniconda3\\lib\\site-packages (25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\slick.aihs\\miniconda3\\lib\\site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\slick.aihs\\miniconda3\\lib\\site-packages (0.45.1)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 â€” Install dependencies (run once)\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip setuptools wheel\n",
    "!{sys.executable} -m pip install --quiet MetaTrader5 pandas numpy python-dateutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a33b0ff-0fa0-4155-84bf-da1cabbe266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DATA_DIR: data\\multiasset\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 â€” Imports & basic config\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MetaTrader5 as mt5\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# directory that Notebook 02 expects\n",
    "DATA_DIR = os.path.join(\"data\", \"multiasset\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(\"âœ… DATA_DIR:\", DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914a9789-55ba-40e3-b350-97edf7ec08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 â€” Symbols, timeframe and dynamic date range\n",
    "SYMBOLS = [\n",
    "    # Volatility Standard\n",
    "    \"Volatility 10 Index\",\n",
    "    \"Volatility 25 Index\",\n",
    "    \"Volatility 50 Index\",\n",
    "    \"Volatility 75 Index\",\n",
    "    \"Volatility 100 Index\",\n",
    "    # Volatility 1s\n",
    "    \"Volatility 10 (1s) Index\",\n",
    "    \"Volatility 25 (1s) Index\",\n",
    "    \"Volatility 50 (1s) Index\",\n",
    "    \"Volatility 75 (1s) Index\",\n",
    "    \"Volatility 100 (1s) Index\",\n",
    "    # Volatility 10s\n",
    "    \"Volatility 10 (10s) Index\",\n",
    "    \"Volatility 25 (10s) Index\",\n",
    "    \"Volatility 50 (10s) Index\",\n",
    "    \"Volatility 75 (10s) Index\",\n",
    "    \"Volatility 100 (10s) Index\",\n",
    "    # Jump\n",
    "    \"Jump 10 Index\",\n",
    "    \"Jump 25 Index\",\n",
    "    \"Jump 50 Index\",\n",
    "    \"Jump 75 Index\",\n",
    "    \"Jump 100 Index\",\n",
    "    # Step\n",
    "    \"Step Index 25\",\n",
    "    \"Step Index 50\",\n",
    "    \"Step Index 75\",\n",
    "    \"Step Index 100\",\n",
    "    # Forex reference\n",
    "    \"EURUSD\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285fd31f-d80e-4639-b157-dff052836e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Symbols: 25 | Timeframe: M15 | Range: 2020-11-14 â†’ 2025-11-14\n"
     ]
    }
   ],
   "source": [
    "# timeframe string (same style as in Notebook 02)\n",
    "TIMEFRAME = \"M15\"   # change if needed\n",
    "\n",
    "# dynamic dates: END_DATE = today, START_DATE = 5 years ago (accounts for leap years)\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "START_DATE = (datetime.now() - relativedelta(years=5)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "MIN_ROWS = 500  # minimum rows after pct-change to accept a symbol\n",
    "\n",
    "# TF map for MetaTrader5\n",
    "TF_MAP = {\n",
    "    \"M1\": mt5.TIMEFRAME_M1, \"M5\": mt5.TIMEFRAME_M5, \"M15\": mt5.TIMEFRAME_M15,\n",
    "    \"M30\": mt5.TIMEFRAME_M30, \"H1\": mt5.TIMEFRAME_H1, \"H4\": mt5.TIMEFRAME_H4,\n",
    "    \"D1\": mt5.TIMEFRAME_D1\n",
    "}\n",
    "tf = TF_MAP[TIMEFRAME.upper()]\n",
    "\n",
    "print(f\"âœ… Symbols: {len(SYMBOLS)} | Timeframe: {TIMEFRAME} | Range: {START_DATE} â†’ {END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e3ecaa-d431-4b71-87fa-45323be779fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 â€” MT5 helpers\n",
    "def mt5_connect():\n",
    "    \"\"\"Initialize MT5. Assumes MT5 terminal is running & logged into Deriv account.\"\"\"\n",
    "    if not mt5.initialize():\n",
    "        raise RuntimeError(\"âŒ MT5 initialize() failed. Start MetaTrader 5 and log in to your Deriv account.\")\n",
    "    acct = mt5.account_info()\n",
    "    if acct is None:\n",
    "        print(\"âš ï¸ Connected to MT5 but account_info() returned None.\")\n",
    "    else:\n",
    "        print(f\"âœ… MT5 connected â€” Login: {getattr(acct,'login',None)}, Balance: {getattr(acct,'balance',None)}\")\n",
    "    return acct\n",
    "\n",
    "def mt5_disconnect():\n",
    "    try:\n",
    "        mt5.shutdown()\n",
    "        print(\"âœ… MT5 shutdown\")\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca09737-1120-497d-a1a3-cc9f4c48fc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MT5 connected â€” Login: 40866995, Balance: 8637.47\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 10 Index\n",
      "  â†’ âš ï¸ No data for Volatility 10 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 25 Index\n",
      "  â†’ âš ï¸ No data for Volatility 25 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 50 Index\n",
      "  â†’ âš ï¸ No data for Volatility 50 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 75 Index\n",
      "  â†’ âš ï¸ No data for Volatility 75 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 100 Index\n",
      "  â†’ âš ï¸ No data for Volatility 100 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 10 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 10 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 25 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 25 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 50 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 50 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 75 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 75 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 100 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 100 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 10 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 10 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 25 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 25 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 50 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 50 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 75 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 75 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 100 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 100 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 10 Index\n",
      "  â†’ âš ï¸ No data for Jump 10 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 25 Index\n",
      "  â†’ âš ï¸ No data for Jump 25 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 50 Index\n",
      "  â†’ âš ï¸ No data for Jump 50 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 75 Index\n",
      "  â†’ âš ï¸ No data for Jump 75 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 100 Index\n",
      "  â†’ âš ï¸ No data for Jump 100 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Step Index 25\n",
      "  â†’ âš ï¸ No data for Step Index 25 â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Step Index 50\n",
      "  â†’ âš ï¸ No data for Step Index 50 â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Step Index 75\n",
      "  â†’ âš ï¸ No data for Step Index 75 â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Step Index 100\n",
      "  â†’ âš ï¸ No data for Step Index 100 â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: EURUSD\n",
      "  â†’ âš ï¸ No data for EURUSD â€” skipped.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 â€” Fetch raw data and save raw CSVs\n",
    "def fetch_and_save_raw(symbols, tf, start_date, end_date, out_dir):\n",
    "    \"\"\"\n",
    "    Fetch OHLCV from MT5 and save raw CSVs (open,high,low,close,volume).\n",
    "    Returns list of saved raw files metadata.\n",
    "    \"\"\"\n",
    "    start_dt, end_dt = pd.to_datetime(start_date), pd.to_datetime(end_date)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    raw_files = []\n",
    "\n",
    "    for sym in symbols:\n",
    "        print(f\"\\nğŸ“¥ Fetching raw: {sym}\")\n",
    "        rates = mt5.copy_rates_range(sym, tf, start_dt.to_pydatetime(), end_dt.to_pydatetime())\n",
    "        if rates is None or len(rates) == 0:\n",
    "            print(f\"  â†’ âš ï¸ No data for {sym} â€” skipped.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.DataFrame(rates)\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "        df.set_index('time', inplace=True)\n",
    "        # standardize columns\n",
    "        df = df[['open', 'high', 'low', 'close', 'tick_volume']].rename(columns={'tick_volume':'volume'})\n",
    "\n",
    "        safe = sym.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        raw_path = os.path.join(out_dir, f\"{safe}_raw.csv\")\n",
    "        df.to_csv(raw_path)\n",
    "        raw_files.append({'symbol': sym, 'safe': safe, 'raw_csv': raw_path})\n",
    "        print(f\"  â†’ âœ… Saved raw: {raw_path} ({len(df)} rows)\")\n",
    "    return raw_files\n",
    "\n",
    "# Example usage:\n",
    "acct = mt5_connect()\n",
    "raw_files = fetch_and_save_raw(SYMBOLS, tf, START_DATE, END_DATE, DATA_DIR)\n",
    "#mt5_disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "440b2840-b235-4477-b1b5-b11a74fd98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 â€” Load raw CSVs (returns dict safe->df)\n",
    "def load_raw_from_disk(data_dir):\n",
    "    raw_files = sorted([p for p in glob.glob(os.path.join(data_dir,\"*_raw.csv\"))])\n",
    "    raw = {}\n",
    "    for p in raw_files:\n",
    "        safe = os.path.basename(p).replace(\"_raw.csv\",\"\")\n",
    "        df = pd.read_csv(p, index_col=0, parse_dates=True)\n",
    "        raw[safe] = df\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f963a1be-0745-416f-8a7c-ed053cce8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 â€” Normalize saved raw files and write normalized results + scalers + asset_to_idx map\n",
    "def normalize_and_save(raw_files_metadata, out_dir, min_rows=MIN_ROWS):\n",
    "    \"\"\"\n",
    "    raw_files_metadata: list of dicts {symbol,safe,raw_csv} or dict safe->df\n",
    "    Produces:\n",
    "      - {safe}_normalized.csv with columns o_pc,h_pc,l_pc,c_pc,v_pc,Close_raw\n",
    "      - {safe}_scaler.csv with mean/std per column\n",
    "    Returns: prepared list of dicts (symbol,safe,csv,scaler)\n",
    "    \"\"\"\n",
    "    prepared = []\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Accept either a list of metadata dicts or a dict safe->df\n",
    "    items = []\n",
    "    if isinstance(raw_files_metadata, dict):\n",
    "        items = [(safe, df) for safe, df in raw_files_metadata.items()]\n",
    "    else:\n",
    "        for item in raw_files_metadata:\n",
    "            safe = item['safe']\n",
    "            df = pd.read_csv(item['raw_csv'], index_col=0, parse_dates=True)\n",
    "            items.append((safe, df))\n",
    "\n",
    "    for safe, df in items:\n",
    "        sym = None\n",
    "        # original symbol may not be available; safe->symbol recovery is not critical\n",
    "        print(f\"\\nâš™ï¸ Preparing: {safe}\")\n",
    "        # compute pct-change features (scale-free)\n",
    "        pct = pd.DataFrame(index=df.index)\n",
    "        pct['o_pc'] = df['open'].pct_change()\n",
    "        pct['h_pc'] = df['high'].pct_change()\n",
    "        pct['l_pc'] = df['low'].pct_change()\n",
    "        pct['c_pc'] = df['close'].pct_change()\n",
    "        pct['v_pc'] = df['volume'].pct_change()\n",
    "        pct.dropna(inplace=True)\n",
    "\n",
    "        if len(pct) < min_rows:\n",
    "            print(f\"  â†’ âš ï¸ Too few rows ({len(pct)}) for {safe}, skipped.\")\n",
    "            continue\n",
    "\n",
    "        # z-score per-asset\n",
    "        means = pct.mean()\n",
    "        stds = pct.std().replace(0, 1.0)\n",
    "        norm = (pct - means) / stds\n",
    "        # Keep raw close for SL/TP/visualization as required by Notebook 02\n",
    "        norm['Close_raw'] = df.loc[norm.index,'close']\n",
    "\n",
    "        csv_path = os.path.join(out_dir, f\"{safe}_normalized.csv\")\n",
    "        scaler_path = os.path.join(out_dir, f\"{safe}_scaler.csv\")\n",
    "        norm.to_csv(csv_path)\n",
    "        pd.DataFrame({'mean': means, 'std': stds}).to_csv(scaler_path)\n",
    "\n",
    "        prepared.append({'symbol': safe, 'safe': safe, 'csv': csv_path, 'scaler': scaler_path})\n",
    "        print(f\"  â†’ âœ… Saved normalized: {csv_path} ({len(norm)} rows), scaler: {scaler_path}\")\n",
    "\n",
    "    # create asset_to_idx.csv mapping safe->index (stable alphabetical order of prepared safes)\n",
    "    safes = [p['safe'] for p in prepared]\n",
    "    asset_map = {safe: i for i, safe in enumerate(safes)}\n",
    "    if asset_map:\n",
    "        pd.Series(asset_map).to_csv(os.path.join(out_dir, \"asset_to_idx.csv\"))\n",
    "        print(\"\\nâœ… Saved asset_to_idx.csv:\", os.path.join(out_dir, \"asset_to_idx.csv\"))\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ No prepared assets to map.\")\n",
    "    return prepared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312f6810-8cd5-4343-9b6a-5379adca0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 â€” One-shot pipeline (connects to MT5, fetches raw, normalizes, and disconnects)\n",
    "def run_full_prep_pipeline(symbols, tf, start_date, end_date, out_dir, min_rows=MIN_ROWS):\n",
    "    acct = mt5_connect()\n",
    "    raw_files = fetch_and_save_raw(symbols, tf, start_date, end_date, out_dir)\n",
    "    # If you want to skip saving raw and normalize already in memory, adapt as needed.\n",
    "    prepared = normalize_and_save(raw_files, out_dir, min_rows=min_rows)\n",
    "    mt5_disconnect()\n",
    "    return prepared\n",
    "\n",
    "# Example usage (uncomment and run):\n",
    "# prepared = run_full_prep_pipeline(SYMBOLS, tf, START_DATE, END_DATE, DATA_DIR, MIN_ROWS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f24889-eccc-4175-9645-79bcce8782a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 â€” Quick check to ensure Notebook 02 can load files\n",
    "def quick_verify(data_dir=DATA_DIR, window=50):\n",
    "    normalized_files = sorted([p for p in glob.glob(os.path.join(data_dir,\"*_normalized.csv\"))])\n",
    "    print(\"Found normalized files:\", len(normalized_files))\n",
    "    for p in normalized_files[:10]:\n",
    "        print(\" -\", os.path.basename(p))\n",
    "        df = pd.read_csv(p, index_col=0, parse_dates=True)\n",
    "        print(\"   columns:\", list(df.columns)[:10], \"rows:\", len(df))\n",
    "    map_path = os.path.join(data_dir,\"asset_to_idx.csv\")\n",
    "    if os.path.exists(map_path):\n",
    "        print(\"Asset map exists:\", map_path)\n",
    "        print(pd.read_csv(map_path, index_col=0).head())\n",
    "    else:\n",
    "        print(\"âš ï¸ asset_to_idx.csv missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f28ab55-21e2-4dbf-9a1e-eae6a2a9090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MT5 connected â€” Login: 40866995, Balance: 8637.47\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 10 Index\n",
      "  â†’ âš ï¸ No data for Volatility 10 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 25 Index\n",
      "  â†’ âš ï¸ No data for Volatility 25 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 50 Index\n",
      "  â†’ âš ï¸ No data for Volatility 50 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 75 Index\n",
      "  â†’ âš ï¸ No data for Volatility 75 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 100 Index\n",
      "  â†’ âš ï¸ No data for Volatility 100 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 10 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 10 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 25 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 25 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 50 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 50 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 75 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 75 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 100 (1s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 100 (1s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 10 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 10 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 25 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 25 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 50 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 50 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 75 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 75 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Volatility 100 (10s) Index\n",
      "  â†’ âš ï¸ No data for Volatility 100 (10s) Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 10 Index\n",
      "  â†’ âš ï¸ No data for Jump 10 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 25 Index\n",
      "  â†’ âš ï¸ No data for Jump 25 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 50 Index\n",
      "  â†’ âš ï¸ No data for Jump 50 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 75 Index\n",
      "  â†’ âš ï¸ No data for Jump 75 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Jump 100 Index\n",
      "  â†’ âš ï¸ No data for Jump 100 Index â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Step Index 25\n",
      "  â†’ âš ï¸ No data for Step Index 25 â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Step Index 50\n",
      "  â†’ âš ï¸ No data for Step Index 50 â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Step Index 75\n",
      "  â†’ âš ï¸ No data for Step Index 75 â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: Step Index 100\n",
      "  â†’ âš ï¸ No data for Step Index 100 â€” skipped.\n",
      "\n",
      "ğŸ“¥ Fetching raw: EURUSD\n",
      "  â†’ âš ï¸ No data for EURUSD â€” skipped.\n",
      "\n",
      "âš ï¸ No prepared assets to map.\n",
      "âœ… MT5 shutdown\n"
     ]
    }
   ],
   "source": [
    "prepared = run_full_prep_pipeline(SYMBOLS, tf, START_DATE, END_DATE, DATA_DIR, MIN_ROWS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ebaca2-c25a-406f-be8e-0b51539a94a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalized files: 0\n",
      "âš ï¸ asset_to_idx.csv missing\n"
     ]
    }
   ],
   "source": [
    "quick_verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95262f3e-f042-4449-bd38-03d9d8bca1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
