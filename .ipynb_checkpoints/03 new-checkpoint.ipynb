{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf2da61-6a8b-47ad-86e4-f4394e14133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\slick\\desktop\\ml\\env\\lib\\site-packages (25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\slick\\desktop\\ml\\env\\lib\\site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\slick\\desktop\\ml\\env\\lib\\site-packages (0.45.1)\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 — optional installs\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip setuptools wheel\n",
    "!{sys.executable} -m pip install --quiet numpy pandas matplotlib seaborn pillow ffmpeg-python MetaTrader5 stable-baselines3 gymnasium==0.29.1 torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b3299a1-6a61-4151-95b5-72d543a6a1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — imports & config\n",
    "import os, glob, json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "DATA_DIR = os.path.join(\"data\", \"multiasset\")\n",
    "MODEL_DIR = os.path.join(\"models\", \"multiasset\")\n",
    "MODEL_FILE = os.path.join(MODEL_DIR, \"ppo_multiasset.zip\")\n",
    "VEC_FILE = os.path.join(MODEL_DIR, \"vec_normalize.pkl\")\n",
    "EMBED_FILE = os.path.join(MODEL_DIR, \"asset_embeddings.npy\")\n",
    "ASSET_MAP_FILE = os.path.join(DATA_DIR, \"asset_to_idx.csv\")\n",
    "\n",
    "WINDOW = 50\n",
    "STARTING_BALANCE = 10_000.0\n",
    "RISK_PER_TRADE = 0.01\n",
    "LEVERAGE = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfd7757-28cb-4784-9bca-fe661a5c696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 datasets\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — load datasets and embeddings\n",
    "def load_normalized_datasets_quick(data_dir=DATA_DIR, window=WINDOW):\n",
    "    csv_files = sorted(glob.glob(os.path.join(data_dir, \"*_normalized.csv\")))\n",
    "    datasets = {}\n",
    "    for p in csv_files:\n",
    "        safe = os.path.basename(p).replace(\"_normalized.csv\",\"\")\n",
    "        df = pd.read_csv(p, index_col=0, parse_dates=True)\n",
    "        df = df[['o_pc','h_pc','l_pc','c_pc','v_pc','Close_raw']].dropna()\n",
    "        if len(df) > window:\n",
    "            datasets[safe] = df\n",
    "    return datasets\n",
    "\n",
    "datasets = load_normalized_datasets_quick(DATA_DIR, WINDOW)\n",
    "embeddings = np.load(EMBED_FILE) if os.path.exists(EMBED_FILE) else np.zeros((len(datasets), EMBED_DIM))\n",
    "asset_map = {s:i for i,s in enumerate(datasets.keys())}\n",
    "print(\"Loaded\", len(datasets), \"datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31d82b8-3e5b-4496-8a5a-6ce21d4063be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — run backtest using the env\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "def run_single_episode(model, datasets, embeddings, asset_map, asset_to_symbol=None, window=WINDOW):\n",
    "    env = MultiAssetEnv(datasets, asset_map, embeddings, asset_to_symbol=asset_to_symbol, window=window)\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        act = extract_action_scalar(action)\n",
    "        obs, reward, done, truncated, info = env.step(act)\n",
    "    return env  # env.trades, env.balance, env.prices etc.\n",
    "\n",
    "def run_backtests(model_file=MODEL_FILE, n_runs=5, asset_to_symbol=None):\n",
    "    model = PPO.load(model_file)\n",
    "    runs = {}\n",
    "    for i in range(n_runs):\n",
    "        env = run_single_episode(model, datasets, embeddings, asset_map, asset_to_symbol, WINDOW)\n",
    "        runs[f\"run{i}\"] = {\"final_balance\": float(env.balance), \"trades\": env.trades, \"prices\": env.prices}\n",
    "        print(f\"Run {i}: final_balance={env.balance:.2f} trades={len(env.trades)}\")\n",
    "    return runs\n",
    "\n",
    "# Example:\n",
    "# model = PPO.load(MODEL_FILE)\n",
    "# runs = run_backtests(MODEL_FILE, n_runs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30674b0f-1442-4cc0-b41d-c4c4ca907920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — metrics helpers\n",
    "def compute_max_drawdown(equity):\n",
    "    arr = np.array(equity)\n",
    "    peaks = np.maximum.accumulate(arr)\n",
    "    dd = (peaks - arr) / peaks\n",
    "    return float(np.nanmax(dd)) if arr.size>0 else 0.0\n",
    "\n",
    "def summarize_runs(runs, starting_balance=STARTING_BALANCE):\n",
    "    rows = []\n",
    "    for k,v in runs.items():\n",
    "        trades = v['trades']\n",
    "        final = v['final_balance']\n",
    "        returns = (final/starting_balance)-1.0\n",
    "        pnl_list = [t.get('pnl',0.0) for t in trades if 'pnl' in t]\n",
    "        equity = [starting_balance] + list(np.cumsum(pnl_list) + starting_balance) if pnl_list else [starting_balance, final]\n",
    "        max_dd = compute_max_drawdown(equity)\n",
    "        rows.append({\"run\":k, \"final_balance\":final, \"return\":returns, \"n_trades\":len(trades), \"max_drawdown\":max_dd})\n",
    "    return pd.DataFrame(rows).sort_values(\"final_balance\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b917e683-e7ac-4e05-a870-009d6afd7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — plotting and export\n",
    "def plot_equity_from_trades(trades, starting_balance=STARTING_BALANCE):\n",
    "    pnl = [t.get('pnl',0.0) for t in trades if 'pnl' in t]\n",
    "    equity = [starting_balance]\n",
    "    for p in pnl:\n",
    "        equity.append(equity[-1] + p)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(equity)\n",
    "    plt.title(\"Equity curve\")\n",
    "    plt.xlabel(\"Trade #\")\n",
    "    plt.ylabel(\"Balance\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def export_trades(runs, out_csv=os.path.join(MODEL_DIR,\"backtest_trades.csv\")):\n",
    "    all_trades = []\n",
    "    for run, v in runs.items():\n",
    "        for t in v['trades']:\n",
    "            row = t.copy()\n",
    "            row['run'] = run\n",
    "            all_trades.append(row)\n",
    "    if not all_trades:\n",
    "        print(\"No trades to export.\")\n",
    "        return None\n",
    "    df = pd.DataFrame(all_trades)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(\"Saved trades to\", out_csv)\n",
    "    return out_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f32b6bc6-ec40-4b58-bc22-5ea425c4f5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_action_scalar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 6 — execute backtests & save\u001b[39;00m\n\u001b[32m      2\u001b[39m model = PPO.load(MODEL_FILE)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m runs = run_backtests(MODEL_FILE, n_runs=\u001b[32m5\u001b[39m, asset_to_symbol={s:s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m datasets.keys()})\n\u001b[32m      4\u001b[39m summary = summarize_runs(runs)\n\u001b[32m      5\u001b[39m display(summary)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mrun_backtests\u001b[39m\u001b[34m(model_file, n_runs, asset_to_symbol)\u001b[39m\n\u001b[32m     16\u001b[39m runs = {}\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     env = run_single_episode(model, datasets, embeddings, asset_map, asset_to_symbol, WINDOW)\n\u001b[32m     19\u001b[39m     runs[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrun\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33mfinal_balance\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(env.balance), \u001b[33m\"\u001b[39m\u001b[33mtrades\u001b[39m\u001b[33m\"\u001b[39m: env.trades, \u001b[33m\"\u001b[39m\u001b[33mprices\u001b[39m\u001b[33m\"\u001b[39m: env.prices}\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: final_balance=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv.balance\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trades=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(env.trades)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mrun_single_episode\u001b[39m\u001b[34m(model, datasets, embeddings, asset_map, asset_to_symbol, window)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m      9\u001b[39m     action, _ = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     act = extract_action_scalar(action)\n\u001b[32m     11\u001b[39m     obs, reward, done, truncated, info = env.step(act)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m env\n",
      "\u001b[31mNameError\u001b[39m: name 'extract_action_scalar' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 6 — execute backtests & save\n",
    "model = PPO.load(MODEL_FILE)\n",
    "runs = run_backtests(MODEL_FILE, n_runs=5, asset_to_symbol={s:s for s in datasets.keys()})\n",
    "summary = summarize_runs(runs)\n",
    "display(summary)\n",
    "export_trades(runs)\n",
    "with open(os.path.join(MODEL_DIR,\"backtest_summary.json\"), \"w\") as fh:\n",
    "    json.dump({\"summary\": summary.to_dict(orient=\"records\"), \"timestamp\": datetime.utcnow().isoformat()}, fh, indent=2)\n",
    "print(\"Saved summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55404b76-c8ec-4fe9-bd12-62eb0b37e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — save animation of last run\n",
    "last_env = run_single_episode(PPO.load(MODEL_FILE), datasets, embeddings, asset_map)\n",
    "anim_path = os.path.join(MODEL_DIR, \"sample_rollout.mp4\")\n",
    "last_env.render(animate=True, save_path=anim_path, fps=12)\n",
    "print(\"Saved animation:\", anim_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
