{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bae9530-d90d-4c7d-bd69-226ac348b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — Imports & config\n",
    "import os, glob, time, json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Config paths (adjust if your layout differs)\n",
    "MODEL_DIR = \"models/multiasset\"\n",
    "MODEL_FILE = os.path.join(MODEL_DIR, \"ppo_multiasset.zip\")   # full path to zip file\n",
    "EMBED_FILE = os.path.join(MODEL_DIR, \"asset_embeddings.npy\")\n",
    "DATA_DIR = os.path.join(\"data\", \"multiasset\")\n",
    "\n",
    "LOG_DIR = os.path.join(MODEL_DIR, \"live_logs\")\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "LOG_FILE = os.path.join(LOG_DIR, \"live_trade_logs.csv\")\n",
    "\n",
    "# Trading / observation settings\n",
    "WINDOW = 50\n",
    "TIMEFRAME = \"M1\"   # human readable timeframe\n",
    "TF_MAP = { \"M1\": mt5.TIMEFRAME_M1, \"M5\": mt5.TIMEFRAME_M5, \"M15\": mt5.TIMEFRAME_M15,\n",
    "           \"M30\": mt5.TIMEFRAME_M30, \"H1\": mt5.TIMEFRAME_H1, \"H4\": mt5.TIMEFRAME_H4,\n",
    "           \"D1\": mt5.TIMEFRAME_D1 }\n",
    "TF_MT5 = TF_MAP[TIMEFRAME.upper()]\n",
    "\n",
    "# Execution / risk params\n",
    "DRY_RUN = True            # switch to False to actually place orders (test on demo first)\n",
    "DEFAULT_RISK_PCT = 0.005  # percent of balance risked (heuristic)\n",
    "MIN_LOT = 0.01\n",
    "MAX_LOT = 1.0\n",
    "\n",
    "# SL/TP/trailing (pips)\n",
    "DEFAULT_SL_PIPS = 20\n",
    "DEFAULT_TP_PIPS = 40\n",
    "TRAIL_PIPS = 15\n",
    "\n",
    "# Limit positions per symbol\n",
    "MAX_POS_PER_SYMBOL = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ea694e-a28d-4fdc-8699-0f7abf9e2b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir contents: ['asset_embeddings.npy', 'live_logs', 'ppo_multiasset.zip', 'tensorboard', 'vec_normalize.pkl']\n",
      "Has model file: True\n",
      "Has embedding: True\n",
      "Scaler CSVs found: 16\n",
      "Normalized CSVs found: 16\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — quick file check\n",
    "print(\"Model dir contents:\", os.listdir(MODEL_DIR))\n",
    "print(\"Has model file:\", os.path.exists(MODEL_FILE))\n",
    "print(\"Has embedding:\", os.path.exists(EMBED_FILE))\n",
    "print(\"Scaler CSVs found:\", len(glob.glob(os.path.join(DATA_DIR, \"*_scaler.csv\"))))\n",
    "print(\"Normalized CSVs found:\", len(glob.glob(os.path.join(DATA_DIR, \"*_normalized.csv\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7c70e7-f18a-44be-9568-03da5cd53f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded assets: 16 ['EURUSD', 'Jump_100_Index', 'Jump_10_Index', 'Jump_25_Index', 'Jump_50_Index', 'Jump_75_Index', 'Volatility_100_1s_Index', 'Volatility_100_Index', 'Volatility_10_1s_Index', 'Volatility_10_Index']\n",
      "Loaded scalers: 16\n",
      "Loaded embeddings: 17\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — loaders & name helpers\n",
    "def make_safe_name(sym: str) -> str:\n",
    "    return sym.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\".\", \"_\")\n",
    "\n",
    "def raw_from_safe(safe: str) -> str:\n",
    "    # Default mapping: replace underscores with spaces (matches how we saved earlier).\n",
    "    # If your MT5 symbols differ, modify this function to return the correct MT5 symbol name.\n",
    "    return safe.replace(\"_\", \" \")\n",
    "\n",
    "# Load scalers (per-asset CSVs)\n",
    "def load_scalers(data_dir=DATA_DIR):\n",
    "    scalers = {}\n",
    "    for p in sorted(glob.glob(os.path.join(data_dir, \"*_scaler.csv\"))):\n",
    "        safe = os.path.basename(p).replace(\"_scaler.csv\",\"\")\n",
    "        df = pd.read_csv(p, index_col=0)\n",
    "        # expect 'mean' and 'std' columns\n",
    "        scalers[safe] = {\"mean\": df[\"mean\"], \"std\": df[\"std\"].replace(0,1.0)}\n",
    "    return scalers\n",
    "\n",
    "# Load normalized datasets (for simulation and index mapping)\n",
    "def load_normalized_datasets(data_dir=DATA_DIR, window=WINDOW):\n",
    "    datasets = {}\n",
    "    for p in sorted(glob.glob(os.path.join(data_dir, \"*_normalized.csv\"))):\n",
    "        safe = os.path.basename(p).replace(\"_normalized.csv\",\"\")\n",
    "        df = pd.read_csv(p, index_col=0, parse_dates=True)\n",
    "        # Expect percent-change columns; attempt to auto-convert if raw columns exist\n",
    "        expected = ['o_pc','h_pc','l_pc','c_pc','v_pc','Close_raw']\n",
    "        if all(c in df.columns for c in expected):\n",
    "            df = df[expected].dropna()\n",
    "        else:\n",
    "            # attempt conversion\n",
    "            if all(c in df.columns for c in ['open','high','low','close','volume']):\n",
    "                tmp = pd.DataFrame(index=df.index)\n",
    "                tmp['o_pc'] = df['open'].pct_change()\n",
    "                tmp['h_pc'] = df['high'].pct_change()\n",
    "                tmp['l_pc'] = df['low'].pct_change()\n",
    "                tmp['c_pc'] = df['close'].pct_change()\n",
    "                tmp['v_pc'] = df['volume'].pct_change()\n",
    "                tmp['Close_raw'] = df['close']\n",
    "                df = tmp.dropna()\n",
    "            else:\n",
    "                raise ValueError(f\"{p} missing expected columns\")\n",
    "        if len(df) > window:\n",
    "            datasets[safe] = df\n",
    "    if not datasets:\n",
    "        raise FileNotFoundError(\"No datasets loaded from \" + data_dir)\n",
    "    return datasets\n",
    "\n",
    "# Load embeddings and map to safe names using asset_to_idx.csv if present\n",
    "def load_embeddings(embed_file=EMBED_FILE, data_dir=DATA_DIR):\n",
    "    emb_dict = {}\n",
    "    if not os.path.exists(embed_file):\n",
    "        print(\"No embedding file:\", embed_file)\n",
    "        return emb_dict\n",
    "    emb = np.load(embed_file, allow_pickle=True)\n",
    "    # load asset_to_idx map if exists\n",
    "    map_path = os.path.join(data_dir, \"asset_to_idx.csv\")\n",
    "    if os.path.exists(map_path):\n",
    "        am = pd.read_csv(map_path, index_col=0, header=None).iloc[:,0].to_dict()\n",
    "        # am may map safe->idx; ensure types right\n",
    "        # am currently looks like {'Volatility_75_Index':0, ...} or similar\n",
    "        for safe, idx in am.items():\n",
    "            idx = int(idx)\n",
    "            if idx < emb.shape[0]:\n",
    "                emb_dict[safe] = emb[idx]\n",
    "    else:\n",
    "        # fallback: map in order of normalized CSVs if same length\n",
    "        csvs = sorted(glob.glob(os.path.join(data_dir, \"*_normalized.csv\")))\n",
    "        safe_list = [os.path.basename(p).replace(\"_normalized.csv\",\"\") for p in csvs]\n",
    "        if len(safe_list) == emb.shape[0]:\n",
    "            for i,safe in enumerate(safe_list):\n",
    "                emb_dict[safe] = emb[i]\n",
    "        else:\n",
    "            print(\"Warning: embedding length and CSV count mismatch; manual mapping required.\")\n",
    "    return emb_dict\n",
    "\n",
    "# Load everything\n",
    "scalers = load_scalers(DATA_DIR)\n",
    "datasets = load_normalized_datasets(DATA_DIR, WINDOW)\n",
    "embeddings = load_embeddings(EMBED_FILE, DATA_DIR)\n",
    "\n",
    "safe_list = list(datasets.keys())\n",
    "print(\"Loaded assets:\", len(safe_list), safe_list[:10])\n",
    "print(\"Loaded scalers:\", len(scalers))\n",
    "print(\"Loaded embeddings:\", len(embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dffb8bd0-a462-426f-80bf-641e16332835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PPO model from models/multiasset\\ppo_multiasset.zip\n",
      "MT5 connected: (500, 5370, '17 Oct 2025')\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — load model & MT5\n",
    "# Load PPO model\n",
    "if not os.path.exists(MODEL_FILE):\n",
    "    raise FileNotFoundError(\"Model file not found at: \" + MODEL_FILE)\n",
    "model = PPO.load(MODEL_FILE)\n",
    "print(\"Loaded PPO model from\", MODEL_FILE)\n",
    "\n",
    "# Initialize MT5\n",
    "if not mt5.initialize():\n",
    "    raise RuntimeError(\"MT5 initialize failed. Open MetaTrader and login.\")\n",
    "print(\"MT5 connected:\", mt5.version())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ffc59-4f27-44b1-8b43-8976573a25a9",
   "metadata": {},
   "source": [
    "# Cell 5 — fetch_and_build_obs used for live inference\n",
    "def fetch_and_build_obs(symbol, window, scalers, embeddings, datasets, safe_list):\n",
    "    \"\"\"\n",
    "    symbol: MT5 symbol name (e.g. 'Volatility 75 Index' or 'EURUSD' depending on broker)\n",
    "    returns: obs (window x features), vol_est, last_price  OR (None,None,None) on failure\n",
    "    \"\"\"\n",
    "    # Transform symbol to safe key: default mapping raw_from_safe inverse\n",
    "    # We assume safe = make_safe_name(symbol) (e.g. \"Volatility 75 Index\" -> \"Volatility_75_Index\")\n",
    "    safe = make_safe_name(symbol)\n",
    "\n",
    "    # Check presence\n",
    "    if safe not in scalers:\n",
    "        print(f\"❌ Missing scaler for: {safe}\")\n",
    "        return None, None, None\n",
    "    if safe not in embeddings:\n",
    "        print(f\"⚠️ Missing embedding for: {safe} — using zeros\")\n",
    "        # you can choose to return None or use zeros; we'll use zeros fallback\n",
    "        emb_vec = np.zeros( (max(1, list(embeddings.values())[0].shape[0]) if embeddings else 8,) )\n",
    "    else:\n",
    "        emb_vec = np.array(embeddings[safe], dtype=np.float32)\n",
    "\n",
    "    # Fetch bars from MT5\n",
    "    count = window + 30\n",
    "    bars = mt5.copy_rates_from_pos(symbol, TF_MT5, 0, count)\n",
    "    if bars is None or len(bars) < window + 2:\n",
    "        print(f\"Insufficient bars for symbol: {symbol} ({0 if bars is None else len(bars)} rows)\")\n",
    "        return None, None, None\n",
    "\n",
    "    df = pd.DataFrame(bars)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df = df.set_index('time')\n",
    "    # rename tick_volume -> volume\n",
    "    if 'tick_volume' in df.columns:\n",
    "        df = df.rename(columns={'tick_volume':'volume'})\n",
    "\n",
    "    # compute pct change and take last window\n",
    "    pct = df[['open','high','low','close','volume']].pct_change().dropna()\n",
    "    if len(pct) < window:\n",
    "        print(f\"Not enough pct rows for {symbol}\")\n",
    "        return None, None, None\n",
    "    pct = pct.tail(window)\n",
    "\n",
    "    # Normalize using stored scaler\n",
    "    scaler = scalers[safe]\n",
    "    cols = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "    # align mean/std (scaler['mean'] is a Series)\n",
    "    try:\n",
    "        mean = scaler[\"mean\"][cols]\n",
    "        std = scaler[\"std\"][cols].replace(0,1.0)\n",
    "    except Exception:\n",
    "        # fallback if scaler is Series with positional order\n",
    "        mean = pd.Series(scaler[\"mean\"].values[:len(cols)], index=cols)\n",
    "        std  = pd.Series(scaler[\"std\"].values[:len(cols)], index=cols).replace(0,1.0)\n",
    "\n",
    "    pct_norm = (pct[cols] - mean) / std\n",
    "    last_price = float(df['close'].iloc[-1])\n",
    "    vol_est = float(pct['close'].std())\n",
    "\n",
    "    # build obs: [pct_norm cols] + embedding repeated + balance_norm + asset_id\n",
    "    emb_rep = np.tile(emb_vec.reshape(1,-1),(window,1)).astype(np.float32) if emb_vec.size>0 else np.zeros((window,0),dtype=np.float32)\n",
    "    balance_col = np.full((window,1), 1.0, dtype=np.float32)\n",
    "    try:\n",
    "        asset_id_val = safe_list.index(safe) / max(1, len(safe_list))\n",
    "    except ValueError:\n",
    "        asset_id_val = 0.0\n",
    "    asset_col = np.full((window,1), asset_id_val, dtype=np.float32)\n",
    "\n",
    "    obs = np.concatenate([pct_norm[cols].values.astype(np.float32), emb_rep, balance_col, asset_col], axis=1)\n",
    "    return obs, vol_est, last_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342785b-63f9-41c4-87c5-5ad3b82cfb21",
   "metadata": {},
   "source": [
    "def fetch_and_build_obs(symbol, window, scalers, embeddings, datasets, safe_list):\n",
    "    \"\"\"\n",
    "    Live inference observation builder.\n",
    "    Must match training shape EXACTLY: (window, 14)\n",
    "    = 5 OHLCV + 1 balance + 8 embedding\n",
    "    \"\"\"\n",
    "    safe = make_safe_name(symbol)\n",
    "\n",
    "    # Scaler check\n",
    "    if safe not in scalers:\n",
    "        print(f\"❌ Missing scaler for: {safe}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Embedding\n",
    "    if safe not in embeddings:\n",
    "        print(f\"⚠️ Missing embedding for {safe}, using zeros\")\n",
    "        emb_vec = np.zeros(8, dtype=np.float32)\n",
    "    else:\n",
    "        emb_vec = np.array(embeddings[safe], dtype=np.float32)\n",
    "\n",
    "    # Fetch MT5 bars\n",
    "    count = window + 30\n",
    "    bars = mt5.copy_rates_from_pos(symbol, TF_MT5, 0, count)\n",
    "\n",
    "    if bars is None or len(bars) < window + 2:\n",
    "        print(f\"❌ Insufficient bars for {symbol}\")\n",
    "        return None, None, None\n",
    "\n",
    "    df = pd.DataFrame(bars)\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\")\n",
    "    df = df.set_index(\"time\")\n",
    "    df = df.rename(columns={\"tick_volume\": \"volume\"})\n",
    "\n",
    "    # Pct-change window\n",
    "    pct = df[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].pct_change().dropna()\n",
    "\n",
    "    if len(pct) < window:\n",
    "        print(f\"❌ Not enough pct rows for {symbol}\")\n",
    "        return None, None, None\n",
    "\n",
    "    pct = pct.tail(window)\n",
    "\n",
    "    # Normalize\n",
    "    scaler = scalers[safe]\n",
    "    cols = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "\n",
    "    mean = scaler[\"mean\"][cols]\n",
    "    std = scaler[\"std\"][cols].replace(0, 1.0)\n",
    "\n",
    "    pct_norm = (pct[cols] - mean) / std\n",
    "\n",
    "    # Last price + volatility\n",
    "    last_price = float(df[\"close\"].iloc[-1])\n",
    "    vol_est = float(pct[\"close\"].std())\n",
    "\n",
    "    # Repeat embedding per timestep\n",
    "    emb_rep = np.tile(emb_vec, (window, 1)).astype(np.float32)\n",
    "\n",
    "    # Balance ONLY (training uses this)\n",
    "    balance_col = np.full((window, 1), 1.0, dtype=np.float32)\n",
    "\n",
    "    # FINAL OBS SHAPE (window, 14)\n",
    "    obs = np.concatenate(\n",
    "        [\n",
    "            pct_norm.values.astype(np.float32),  # 5\n",
    "            balance_col,                         # 1\n",
    "            emb_rep                              # 8\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return obs, vol_est, last_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a21ede8-f568-4a20-b247-c1bf11905ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_build_obs(raw_symbol, window, scalers, embeddings, datasets, safe_list):\n",
    "    safe = safe_from_raw(raw_symbol)\n",
    "\n",
    "    if safe not in datasets:\n",
    "        print(\"No dataset for\", safe)\n",
    "        return None, None, None\n",
    "\n",
    "    df = datasets[safe]\n",
    "\n",
    "    # Check minimum length\n",
    "    if len(df) < window:\n",
    "        print(\"Not enough data for\", safe)\n",
    "        return None, None, None\n",
    "\n",
    "    # ---- FIX HERE: Use correct column names ----\n",
    "    try:\n",
    "        window_df = df.iloc[-window:]\n",
    "\n",
    "        features = window_df[['o_pc', 'h_pc', 'l_pc', 'c_pc', 'v_pc']].values\n",
    "        last_price = float(window_df['Close_raw'].iloc[-1])\n",
    "    except KeyError as e:\n",
    "        print(\"Column missing:\", e)\n",
    "        print(\"Available columns:\", df.columns)\n",
    "        return None, None, None\n",
    "    # --------------------------------------------\n",
    "\n",
    "    # Scale\n",
    "    scaler = scalers[safe]\n",
    "    features_scaled = scaler.transform(features)\n",
    "\n",
    "    # Embedding vector\n",
    "    embed = embeddings[safe]  # shape (embed_dim,)\n",
    "\n",
    "    # Final obs shape: (window, 5 + embed_dim)\n",
    "    obs = np.hstack([features_scaled, np.repeat(embed[np.newaxis, :], window, axis=0)])\n",
    "\n",
    "    # Compute volatility\n",
    "    vol = np.std(window_df['c_pc'].values)\n",
    "\n",
    "    return obs.astype(np.float32), float(vol), last_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eab4f5f3-ece6-45c6-a69f-5cba576c2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — execution helpers\n",
    "def pip_value(symbol):\n",
    "    # crude: JPY pairs differ\n",
    "    if \"JPY\" in symbol or \"JPY\" in symbol.upper():\n",
    "        return 0.01\n",
    "    return 0.0001\n",
    "\n",
    "def compute_lot_from_balance(balance, vol, price, risk_pct=DEFAULT_RISK_PCT, min_lot=MIN_LOT, max_lot=MAX_LOT):\n",
    "    # heuristic sizing\n",
    "    risk_amount = balance * risk_pct\n",
    "    vol = max(vol, 1e-8)\n",
    "    price_scale = 1000.0\n",
    "    lot = risk_amount / (vol * price_scale)\n",
    "    lot = max(min_lot, min(max_lot, round(lot, 2)))\n",
    "    return float(lot)\n",
    "\n",
    "def compute_sl_tp_by_pips(symbol, price, direction, sl_pips=DEFAULT_SL_PIPS, tp_pips=DEFAULT_TP_PIPS):\n",
    "    pip = pip_value(symbol)\n",
    "    if direction == \"BUY\":\n",
    "        sl = price - sl_pips * pip\n",
    "        tp = price + tp_pips * pip\n",
    "    else:\n",
    "        sl = price + sl_pips * pip\n",
    "        tp = price - tp_pips * pip\n",
    "    return float(sl), float(tp)\n",
    "\n",
    "def trailing_sl_level(symbol, pos, trail_pips=TRAIL_PIPS):\n",
    "    \"\"\"\n",
    "    pos: mt5.Position-like object (position returned from mt5.positions_get)\n",
    "    returns new_sl_value or None\n",
    "    \"\"\"\n",
    "    tick = mt5.symbol_info_tick(pos.symbol)\n",
    "    if tick is None: \n",
    "        return None\n",
    "    pip = pip_value(pos.symbol)\n",
    "    if pos.type == 0:  # BUY position type==0 (depends on MT5 build)\n",
    "        current = float(tick.bid)\n",
    "        new_sl = current - trail_pips * pip\n",
    "        # only move SL up (for buy)\n",
    "        if pos.sl is None or new_sl > pos.sl:\n",
    "            return float(new_sl)\n",
    "    else:  # SELL\n",
    "        current = float(tick.ask)\n",
    "        new_sl = current + trail_pips * pip\n",
    "        if pos.sl is None or new_sl < pos.sl:\n",
    "            return float(new_sl)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4dfd36f-3427-437e-b48d-539900ebb3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — order and management helpers\n",
    "def get_positions_for_symbol(symbol):\n",
    "    pos = mt5.positions_get(symbol=symbol)\n",
    "    return [] if pos is None else list(pos)\n",
    "\n",
    "def place_market_order(symbol, direction, lot, sl, tp, comment=\"multiasset_live\"):\n",
    "    \"\"\"\n",
    "    direction: \"BUY\" or \"SELL\"\n",
    "    returns result object or simulated dict when DRY_RUN=True\n",
    "    \"\"\"\n",
    "    tick = mt5.symbol_info_tick(symbol)\n",
    "    if tick is None:\n",
    "        print(\"❌ No tick for\", symbol)\n",
    "        return None\n",
    "    price = float(tick.ask if direction==\"BUY\" else tick.bid)\n",
    "    if DRY_RUN:\n",
    "        return {\"retcode\": 10009, \"price\": price, \"comment\":\"DRY_RUN\", \"direction\":direction}\n",
    "    request = {\n",
    "        \"action\": mt5.TRADE_ACTION_DEAL,\n",
    "        \"symbol\": symbol,\n",
    "        \"volume\": float(lot),\n",
    "        \"type\": mt5.ORDER_TYPE_BUY if direction==\"BUY\" else mt5.ORDER_TYPE_SELL,\n",
    "        \"price\": price,\n",
    "        \"sl\": float(sl) if sl is not None else 0.0,\n",
    "        \"tp\": float(tp) if tp is not None else 0.0,\n",
    "        \"deviation\": 20,\n",
    "        \"magic\": 234000,\n",
    "        \"comment\": comment,\n",
    "        \"type_filling\": mt5.ORDER_FILLING_FOK,\n",
    "    }\n",
    "    res = mt5.order_send(request)\n",
    "    return res\n",
    "\n",
    "def close_position_by_ticket(ticket, volume=None):\n",
    "    # get position info:\n",
    "    pos = None\n",
    "    pos_list = mt5.positions_get(ticket=ticket)\n",
    "    if pos_list: pos = pos_list[0]\n",
    "    if pos is None:\n",
    "        print(\"No position with ticket\", ticket)\n",
    "        return None\n",
    "    symbol = pos.symbol\n",
    "    if pos.type == 0:  # long => close with SELL\n",
    "        order_type = mt5.ORDER_TYPE_SELL\n",
    "        price = mt5.symbol_info_tick(symbol).bid\n",
    "    else:\n",
    "        order_type = mt5.ORDER_TYPE_BUY\n",
    "        price = mt5.symbol_info_tick(symbol).ask\n",
    "    req = {\n",
    "        \"action\": mt5.TRADE_ACTION_DEAL,\n",
    "        \"symbol\": symbol,\n",
    "        \"volume\": float(volume if volume is not None else pos.volume),\n",
    "        \"type\": order_type,\n",
    "        \"position\": int(ticket),\n",
    "        \"price\": price,\n",
    "        \"deviation\": 20,\n",
    "        \"magic\": 234000,\n",
    "        \"comment\": \"auto_close\",\n",
    "        \"type_filling\": mt5.ORDER_FILLING_FOK\n",
    "    }\n",
    "    if DRY_RUN:\n",
    "        return {\"retcode\": 10009, \"comment\":\"DRY_RUN_CLOSE\", \"ticket\": ticket}\n",
    "    return mt5.order_send(req)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac0eda29-5f00-4e53-87b3-30449e185f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 — single-pass predictor + order manager\n",
    "def run_once_predict_and_manage(model, safe_list, scalers, embeddings, datasets):\n",
    "    \"\"\"\n",
    "    Loop over all assets (Option A), predict, place orders, auto-close on reversal,\n",
    "    enforce MAX_POS_PER_SYMBOL, apply trailing SL.\n",
    "    \"\"\"\n",
    "    # Use raw symbol names for MT5 by default: raw = safe.replace('_',' ')\n",
    "    raw_symbols = [raw_from_safe(s) for s in safe_list]\n",
    "\n",
    "    # account balance\n",
    "    acct = mt5.account_info()\n",
    "    balance = float(acct.balance) if acct else 10000.0\n",
    "\n",
    "    # prepare log header\n",
    "    header = not os.path.exists(LOG_FILE)\n",
    "\n",
    "    for safe, raw in zip(safe_list, raw_symbols):\n",
    "        print(\"\\n---\", raw, \"(\", safe, \") ---\")\n",
    "        obs, vol, last_price = fetch_and_build_obs(raw, WINDOW, scalers, embeddings, datasets, safe_list)\n",
    "        if obs is None:\n",
    "            print(\"Skip\", raw)\n",
    "            continue\n",
    "\n",
    "        # predict\n",
    "        try:\n",
    "            action, _ = model.predict(obs[np.newaxis,...], deterministic=True)\n",
    "            a = int(action[0]) if isinstance(action, (list,tuple,np.ndarray)) else int(action)\n",
    "        except Exception as e:\n",
    "            print(\"Prediction error:\", e)\n",
    "            continue\n",
    "\n",
    "        positions = get_positions_for_symbol(raw)\n",
    "        print(\"Existing positions:\", len(positions))\n",
    "\n",
    "        # Auto-close on reversal: if signal BUY and existing SELL positions exist -> close them\n",
    "        if a == 1:\n",
    "            # BUY signal -> close SELL positions (p.type==1 typically)\n",
    "            for p in positions:\n",
    "                # depending on MT5 build, p.type: 0 = BUY, 1 = SELL (sometimes reversed). Check type semantics in your MT5.\n",
    "                if getattr(p, \"type\", None) == 1:\n",
    "                    print(\"Closing opposing SELL position ticket\", p.ticket)\n",
    "                    close_position_by_ticket(p.ticket)\n",
    "        elif a == 2:\n",
    "            for p in positions:\n",
    "                if getattr(p, \"type\", None) == 0:\n",
    "                    print(\"Closing opposing BUY position ticket\", p.ticket)\n",
    "                    close_position_by_ticket(p.ticket)\n",
    "\n",
    "        # Re-fetch positions and enforce limit\n",
    "        positions = get_positions_for_symbol(raw)\n",
    "        if len(positions) >= MAX_POS_PER_SYMBOL:\n",
    "            print(f\"Max positions for {raw} reached ({len(positions)}) — skipping open\")\n",
    "        else:\n",
    "            if a == 0:\n",
    "                print(\"HOLD\")\n",
    "            else:\n",
    "                direction = \"BUY\" if a==1 else \"SELL\"\n",
    "                lot = compute_lot_from_balance(balance, vol, last_price)\n",
    "                sl, tp = compute_sl_tp_by_pips(raw, last_price, direction, DEFAULT_SL_PIPS, DEFAULT_TP_PIPS)\n",
    "                res = place_market_order(raw, direction, lot, sl, tp)\n",
    "                # normalize response for logging\n",
    "                if isinstance(res, dict):\n",
    "                    retcode = res.get(\"retcode\")\n",
    "                    comment = res.get(\"comment\")\n",
    "                    price_executed = res.get(\"price\", last_price)\n",
    "                else:\n",
    "                    retcode = getattr(res, \"retcode\", None)\n",
    "                    comment = getattr(res, \"comment\", \"\")\n",
    "                    price_executed = last_price\n",
    "                entry = {\n",
    "                    \"timestamp\": datetime.utcnow().isoformat(),\n",
    "                    \"safe\": safe,\n",
    "                    \"symbol\": raw,\n",
    "                    \"action\": direction,\n",
    "                    \"lot\": lot,\n",
    "                    \"exec_price\": price_executed,\n",
    "                    \"sl\": sl,\n",
    "                    \"tp\": tp,\n",
    "                    \"retcode\": retcode,\n",
    "                    \"comment\": comment,\n",
    "                    \"dry_run\": DRY_RUN\n",
    "                }\n",
    "                pd.DataFrame([entry]).to_csv(LOG_FILE, mode=\"a\", index=False, header=header)\n",
    "                header = False\n",
    "                print(\"Placed\", direction, \"lot\", lot, \"retcode\", retcode)\n",
    "\n",
    "        # Trailing SL update for open positions\n",
    "        for p in get_positions_for_symbol(raw):\n",
    "            new_sl = trailing_sl_level(raw, p, TRAIL_PIPS=TRAIL_PIPS) if False else trailing_sl_level(raw, p, trail_pips=TRAIL_PIPS)\n",
    "            if new_sl:\n",
    "                # send modify order to change SL: in MT5, use trade position modify, we'll call order_send with TRADE_ACTION_SLTP or use position modification wrapper\n",
    "                # Simple approach: send request to set SL/TP using ORDER_TYPE: mt5.ORDER_TYPE_BUY/SELL? use trade_modify if available\n",
    "                # Use mt5.order_send with action TRADE_ACTION_SLTP if supported:\n",
    "                req = {\n",
    "                    \"action\": mt5.TRADE_ACTION_SLTP,\n",
    "                    \"symbol\": raw,\n",
    "                    \"position\": int(p.ticket),\n",
    "                    \"sl\": new_sl,\n",
    "                    \"tp\": float(p.tp) if getattr(p, \"tp\", None) is not None else 0.0,\n",
    "                }\n",
    "                if DRY_RUN:\n",
    "                    print(f\"[DRY] Would modify SL for ticket {p.ticket} -> {new_sl}\")\n",
    "                else:\n",
    "                    r = mt5.order_send(req)\n",
    "                    print(\"Modify SL result:\", getattr(r,\"retcode\", None))\n",
    "\n",
    "    print(\"\\nSingle pass complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0857233-ed9a-4e0e-ba62-56eea9981fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_from_raw(raw_symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert MT5 raw name to safe key:\n",
    "    'Volatility 75 Index' → 'Volatility_75_Index'\n",
    "    \"\"\"\n",
    "    return raw_symbol.replace(\" \", \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d815ed13-335d-4dc4-9e5e-e9ac3b604c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_from_safe(safe_symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert safe key to raw MT5 name:\n",
    "    'Volatility_75_Index' → 'Volatility 75 Index'\n",
    "    \"\"\"\n",
    "    return safe_symbol.replace(\"_\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b492ca5-51e3-44e9-be7a-bb418e2db3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EURUSD <__main__.MiniScaler object at 0x000001E9B064B770>\n"
     ]
    }
   ],
   "source": [
    "print(safe, scalers[safe])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d54039d-5786-4dd9-9831-be3314cf2cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.MiniScaler'>\n"
     ]
    }
   ],
   "source": [
    "print(type(scalers[safe]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc30b2ab-2211-4c95-870e-6f06c5a7c4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading assets (safe names): ['EURUSD', 'Jump_100_Index', 'Jump_10_Index', 'Jump_25_Index', 'Jump_50_Index', 'Jump_75_Index', 'Volatility_100_1s_Index', 'Volatility_100_Index', 'Volatility_10_1s_Index', 'Volatility_10_Index', 'Volatility_25_1s_Index', 'Volatility_25_Index', 'Volatility_50_1s_Index', 'Volatility_50_Index', 'Volatility_75_1s_Index', 'Volatility_75_Index']\n",
      "\n",
      "--- EURUSD ( EURUSD ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Jump 100 Index ( Jump_100_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Jump 10 Index ( Jump_10_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "( Jump_25_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Jump 50 Index ( Jump_50_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Jump 75 Index ( Jump_75_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 100 1s Index ( Volatility_100_1s_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 100 Index ( Volatility_100_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 10 1s Index ( Volatility_10_1s_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 10 Index ( Volatility_10_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 25 1s Index ( Volatility_25_1s_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 25 Index ( Volatility_25_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 50 1s Index ( Volatility_50_1s_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 50 Index ( Volatility_50_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 75 1s Index ( Volatility_75_1s_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "--- Volatility 75 Index ( Volatility_75_Index ) ---\n",
      "Prediction error: Error: Unexpected observation shape (1, 50, 13) for Box environment, please use (50, 14) or (n_env, 50, 14) for the observation shape.\n",
      "\n",
      "Single pass complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 — run once (recommended)\n",
    "# Trade Option A: all assets present in datasets\n",
    "safe_list = list(datasets.keys())\n",
    "print(\"Trading assets (safe names):\", safe_list)\n",
    "run_once_predict_and_manage(model, safe_list, scalers, embeddings, datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0834dbb7-5c7d-4b87-9051-1c9fb3f1033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniScaler:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return (x - self.mean) / self.std\n",
    "    \n",
    "    def inverse_transform(self, x):\n",
    "        return x * self.std + self.mean\n",
    "\n",
    "# Fix for all symbols\n",
    "for sym in scalers:\n",
    "    mean = scalers[sym][\"mean\"].values.astype(np.float32)\n",
    "    std = scalers[sym][\"std\"].values.astype(np.float32)\n",
    "    scalers[sym] = MiniScaler(mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329d56f-6792-4628-8f67-ed309566dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 — simulation evaluator (quick/backtest style)\n",
    "def simulate_trades_on_history(datasets, model, assets=None, window=WINDOW, horizon=10):\n",
    "    trades = []\n",
    "    assets = assets or list(datasets.keys())\n",
    "    for safe in assets:\n",
    "        df = datasets[safe].reset_index(drop=True)\n",
    "        emb = embeddings.get(safe, np.zeros( (0,) ))\n",
    "        for i in range(window, len(df)-horizon):\n",
    "            window_df = df.iloc[i-window:i]\n",
    "            feat = window_df[['o_pc','h_pc','l_pc','c_pc','v_pc']].values.astype(np.float32)\n",
    "            emb_rep = np.tile(emb.reshape(1,-1),(window,1)) if emb.size>0 else np.zeros((window,0),dtype=np.float32)\n",
    "            balance_col = np.full((window,1),1.0,dtype=np.float32)\n",
    "            asset_id = np.full((window,1), list(datasets.keys()).index(safe)/len(datasets), dtype=np.float32)\n",
    "            obs = np.concatenate([feat, emb_rep, balance_col, asset_id], axis=1)\n",
    "            try:\n",
    "                action, _ = model.predict(obs[np.newaxis,...], deterministic=True)\n",
    "                action = int(action[0]) if isinstance(action,(list,tuple,np.ndarray)) else int(action)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if action == 0: \n",
    "                continue\n",
    "            entry_price = float(df['Close_raw'].iat[i-1])\n",
    "            exit_price = float(df['Close_raw'].iat[i+horizon-1])\n",
    "            pos = 1 if action==1 else -1\n",
    "            pnl = (exit_price - entry_price)/entry_price * pos\n",
    "            trades.append({\"safe\": safe, \"entry_i\": i, \"horizon\": horizon, \"action\": action, \"pnl\": pnl})\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    return trades_df\n",
    "\n",
    "def compute_trade_metrics(trades_df):\n",
    "    if trades_df.empty:\n",
    "        return {}\n",
    "    pnl = trades_df['pnl']\n",
    "    total = pnl.sum()\n",
    "    mean = pnl.mean()\n",
    "    std = pnl.std()\n",
    "    wins = (pnl>0).sum()\n",
    "    losses = (pnl<=0).sum()\n",
    "    win_rate = wins / (wins+losses) if (wins+losses)>0 else 0.0\n",
    "    profit_factor = (pnl[pnl>0].sum() / abs(pnl[pnl<0].sum())) if (pnl[pnl<0].sum()!=0) else np.nan\n",
    "    cum = pnl.cumsum()\n",
    "    max_dd = (cum.cummax() - cum).max()\n",
    "    return {\"n_trades\": len(pnl), \"total_pnl\": float(total), \"mean\": float(mean), \"std\": float(std),\n",
    "            \"win_rate\": float(win_rate), \"profit_factor\": float(profit_factor), \"max_drawdown\": float(max_dd)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bd76b-dcfb-4ffb-a7a9-2c9fa7dbfb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 — run simulation (may take a few minutes depending on dataset size)\n",
    "sim_trades = simulate_trades_on_history(datasets, model, assets=list(datasets.keys()), window=WINDOW, horizon=10)\n",
    "sim_trades.to_csv(os.path.join(MODEL_DIR, \"simulated_trades_optionA.csv\"), index=False)\n",
    "metrics = compute_trade_metrics(sim_trades)\n",
    "print(\"Simulation metrics:\", json.dumps(metrics, indent=2))\n",
    "if not sim_trades.empty:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.hist(sim_trades['pnl'], bins=60)\n",
    "    plt.title(\"Distribution of simulated trade returns\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c93902-3358-4cb6-ab95-7cee1ae37426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 — show last live logs\n",
    "if os.path.exists(LOG_FILE):\n",
    "    df_log = pd.read_csv(LOG_FILE)\n",
    "    display(df_log.tail(20))\n",
    "else:\n",
    "    print(\"No live log present:\", LOG_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
